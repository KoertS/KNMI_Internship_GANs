{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ds = '/nobackup/users/schreurs/project_GAN/dataset_np/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[38;5;33m201812170755_201812180800\u001b[0m/\r\n",
      "\u001b[38;5;33m20190103T080500_20190104T080000\u001b[0m/\r\n",
      "\u001b[38;5;33m20190111T080500_20190112T080000\u001b[0m/\r\n",
      "\u001b[38;5;33m20190114T080500_20190115T080000\u001b[0m/\r\n",
      "\u001b[38;5;33m20190118T080500_20190119T080000\u001b[0m/\r\n",
      "\u001b[38;5;33m20190121T080500_20190122T080000\u001b[0m/\r\n",
      "\u001b[38;5;33m20190123T080500_20190124T080000\u001b[0m/\r\n",
      "\u001b[38;5;33m20190228T080500_20190301T080000\u001b[0m/\r\n",
      "\u001b[38;5;33m20190305T080500_20190306T080000\u001b[0m/\r\n",
      "\u001b[38;5;33m20190316T080500_20190317T080000\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls /nobackup/users/schreurs/project_GAN/dataset_np | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [f for f in os.listdir(path_ds) if os.path.isdir(os.path.join(path_ds, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/nobackup/users/schreurs/project_GAN/dataset_np/201812170755_201812180800'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-eb703439dadd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_ds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/nobackup/users/schreurs/project_GAN/dataset_np/201812170755_201812180800'"
     ]
    }
   ],
   "source": [
    "path_folder = path_ds + folders[0]\n",
    "\n",
    "with np.load(path_folder) as data:\n",
    "    timestamp = data[0]\n",
    "    labels = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pdb\n",
    "import pdb\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras import layers, initializers\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from natsort import natsorted\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "#################################################################\n",
    "\n",
    "#File Paths\n",
    "dataset_path = '/nobackup/users/schreurs/project_GAN/dataset_np/*'\n",
    "\n",
    "\n",
    "data_files = natsorted(glob.glob(text_path)) # Load the array filenames\n",
    "\n",
    "text_train = text_files[:round(0.9*len(text_files))]\n",
    "tags_train = tags_files[:round(0.9*len(tags_files))]\n",
    "\n",
    "#Parameters\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "index = 0\n",
    "PADDING_LENGTH = 768\n",
    "BATCH_LENGTH = 1\n",
    "LEARNING_RATE = 0.01\n",
    "OPTIMISER = 'ADAM'\n",
    "\n",
    "            #Define the training parameters here.\n",
    "#################################################################\n",
    "\n",
    "#@tf.function\n",
    "def load_files(filename1, filename2):\n",
    "    tags = np.load(filename[1], allow_pickle=True)\n",
    "    arr = np.load(filename[0], allow_pickle=True)\n",
    "\n",
    "    # Perform padding and convert back to tensor\n",
    "\n",
    "    return arr, tags\n",
    "\n",
    "def load_dataset(text_files, tag_files):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices([text_files, tag_files])\n",
    "    print(dataset)\n",
    "    #dataset = dataset.map(load_files)\n",
    "    #dataset = dataset.map(lambda x: tf.py_function(load_files, [x], tf.float64))\n",
    "    dataset = dataset.map(map_func=load_files, num_parallel_calls=AUTO)\n",
    "    return dataset\n",
    "\n",
    "def get_batch_dataset(filename1, filename2):\n",
    "    dataset = load_dataset(filename1, filename2)\n",
    "    dataset = dataset.batch(BATCH_LENGTH)\n",
    "    dataset = dataset.prefetch(AUTO).repeat()\n",
    "    return dataset\n",
    "\n",
    "def get_training_dataset():\n",
    "    return get_batch_dataset(text_train, tags_train) \n",
    "\n",
    "\n",
    "dataset = get_batch_dataset(text_train, tags_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
